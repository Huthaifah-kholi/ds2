{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons and SGD  \n",
    "In scikit learn, there is a (one layer) perceptron binary classifier that is the basis of multi-layer neural nets. It is similar to stochastic gradient descent SGD). Here, we run both on the whole Iris dataset focusing on classifying one species against the rest.  \n",
    "Scikit-learn has multi-layer perceptrons as well but they are not suitable for heavy processing. Here, we use them on the breast cancer set (binary) and Iris (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.linear_model import SGDClassifier, Perceptron\n",
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = (iris.target == 0).astype(np.int) # is it setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "clf_p = Perceptron(random_state = 777)\n",
    "clf_s = SGDClassifier()\n",
    "clf_p.fit(X,y)\n",
    "clf_s.fit(X,y)\n",
    "print(clf_p.predict([[5.1,3.3,1.5,.3]]))\n",
    "print(clf_s.predict([[3.1,3.3,1.5,1.3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False) [[  7.43281875  21.72670097 -34.30531732 -14.86563751]] [ 9.92051582]\n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=5, n_jobs=1, penalty=None, random_state=777, shuffle=True,\n",
      "      verbose=0, warm_start=False) [[ 2.6  5.9 -8.9 -3.9]] [ 1.]\n"
     ]
    }
   ],
   "source": [
    "print(clf_s, clf_s.coef_, clf_s.intercept_)\n",
    "print(clf_p, clf_p.coef_, clf_p.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "scaler = StandardScaler()\n",
    "X = cancer['data']\n",
    "y = cancer['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state=707)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(90, 60, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 layers, with 90, 60 and 30 neurons \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(90,60,30), activation='tanh', max_iter=300) \n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  2]\n",
      " [ 2 88]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        53\n",
      "          1       0.98      0.98      0.98        90\n",
      "\n",
      "avg / total       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mlp.coefs_[3]) # for each layer neurons, weights\n",
    "#print(mlp.intercepts_[0]) # for each layer, biases per neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 classes, iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = iris.data  # iris defined above\n",
    "y2 = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, stratify=y2, train_size=0.75, random_state=717)\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X2_train)\n",
    "X2_train = scaler2.transform(X2_train)\n",
    "X2_test = scaler2.transform(X2_test)\n",
    "mlp2 = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(4,8,4,8,4), \n",
    "                     activation='tanh', max_iter=300, random_state = 0) # \n",
    "mlp2.fit(X2_train,y2_train)\n",
    "predictions2 = mlp2.predict(X2_test)\n",
    "print(confusion_matrix(y2_test,predictions2))\n",
    "print(classification_report(y2_test,predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(90, 60, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:   \n",
    "This does not mean we achieved perfect prediction. Change the splitted samples using another random state and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
