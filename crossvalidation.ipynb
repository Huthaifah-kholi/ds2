{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation and grid search - iris dataset, logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need some imports \n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.96666667  0.96666667  1.          0.96666667  0.9       ]\n",
      "Average cross-validation score: 0.96 +/- 0.03\n"
     ]
    }
   ],
   "source": [
    "# load iris and do some cross validation tests\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression(C=10, max_iter=200, n_jobs=3,solver='liblinear') \n",
    "# C=1, max_iter=100, solver='liblinear' 'newton-cg', 'lbfgs', 'liblinear', 'sag'\n",
    "np.random.seed(79) # this (np rng) is used when [random_state=None]. Can also set directly random_state=79 \n",
    "# shuffling is similar to stratification\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=None) # shuffle= False by default, use cv=3 in next step\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv = kf) # cv=3 as good as cv = 5, prev. step not needed\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f} +/- {:.2f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search  \n",
    "Using iris dataset, we split dataset, run grid search on train data, predict test data using optimized classifier (best parameters) and evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'max_iter': 100}\n",
      "Best cross-validation score: 0.97\n",
      "Test set score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# do a train test split at 70% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size = 0.7, random_state=0)\n",
    "\n",
    "# define a logistic regression classifier with some initial values (set n_jobs to 1 if only one core)\n",
    "clf  = LogisticRegression(n_jobs=3,solver='liblinear')\n",
    "\n",
    "# define a paramter grid (dictionaries) of parameters to try\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "# define grid search with validation using 3 folds (stratified by default)\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "\n",
    "# gridsearch is now a classifier with best parameters\n",
    "grid_search.fit(X_train, y_train) # gridsearch finds best parameters & fits the whole train data, ready to predict\n",
    "\n",
    "# print best parameters and best score\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# check test score\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test))) # score predicts first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 16  2]\n",
      " [ 0  0 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      0.89      0.94        18\n",
      "          2       0.85      1.00      0.92        11\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict values using optimized model\n",
    "preds = grid_search.predict(X_test)\n",
    "\n",
    "# print confusion matrix and performance on test set\n",
    "print(confusion_matrix(y_test,preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=3,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
